{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07eb690d",
   "metadata": {},
   "source": [
    "# Qwen2.5-VL Demand Letter Spark Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import os, json, uuid, threading\n",
    "import fitz\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydantic import BaseModel, Field\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DemandLetterQwen2_5_VL\").getOrCreate()\n",
    "print(\"Spark version:\", spark.version)\n",
    "print(\"CUDA:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64871d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2\n",
    "class DemandLetterExtract(BaseModel):\n",
    "    is_demand_letter: bool|None=None\n",
    "    claim_number: str|None=None\n",
    "    claimant_name: str|None=None\n",
    "    claimant_address: str|None=None\n",
    "    claimant_contact_phone: str|None=None\n",
    "    claimant_contact_email: str|None=None\n",
    "    claimant_contact_facsimile: str|None=None\n",
    "    claimant_legal_office_information: str|None=None\n",
    "    insurance_company_representative: str|None=None\n",
    "    claim_amount: str|None=None\n",
    "    demand_letter_date: str|None=None\n",
    "    response_deadline_date: str|None=None\n",
    "    evidence_attached: list = Field(default_factory=list)\n",
    "    date_of_loss: str|None=None\n",
    "    insured_property_address: str|None=None\n",
    "    insured_asset_description: str|None=None\n",
    "    policy_number: str|None=None\n",
    "    referenced_policy_language: str|None=None\n",
    "    threats_of_legal_action: str|None=None\n",
    "    requested_resolution: str|None=None\n",
    "    tone_of_letter: str|None=None\n",
    "    claimant_stated_cause_of_loss: str|None=None\n",
    "    letter_response_markdown: str|None=None\n",
    "\n",
    "MASTER_PROMPT = \"\"\"You are an insurance claims adjuster analyzing a document containing both text and images (PDF page snapshots). \n",
    "Use ALL provided content — extracted text AND page images — to determine if the document is a demand letter and to extract structured data.  \n",
    "Images always override text in cases of conflict.\n",
    "\n",
    "Your job is to produce ONLY a JSON object matching the exact schema below, with no commentary, no Markdown, and no extra fields:\n",
    "\n",
    "{{\n",
    "    \"is_demand_letter\": boolean | false,\n",
    "    \"claim_number\": string | null,\n",
    "    \"claimant_name\": string | null,\n",
    "    \"claimant_address\": string | null,\n",
    "    \"claimant_contact_phone\": string | null,\n",
    "    \"claimant_contact_email\": string | null,\n",
    "    \"claimant_contact_facsimile\": string | null,\n",
    "    \"claimant_legal_office_information\": string | null,\n",
    "    \"insurance_company_representative\": string | null,\n",
    "    \"claim_amount\": string | null,\n",
    "    \"demand_letter_date\": string | null,\n",
    "    \"response_deadline_date\": string | null,\n",
    "    \"evidence_attached\": array,\n",
    "    \"date_of_loss\": string | null,\n",
    "    \"insured_property_address\": string | null,\n",
    "    \"insured_asset_description\": string | null,\n",
    "    \"policy_number\": string | null,\n",
    "    \"referenced_policy_language\": string | null,\n",
    "    \"threats_of_legal_action\": string | null,\n",
    "    \"requested_resolution\": string | null,\n",
    "    \"tone_of_letter\": string | null,\n",
    "    \"claimant_stated_cause_of_loss\": string | null,\n",
    "    \"letter_response_markdown\": string | null\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "\n",
    "1. Use BOTH:  \n",
    "   - The extracted TEXT of the PDF pages  \n",
    "   - The IMAGE representations of the pages  \n",
    "   If there is any discrepancy, treat the IMAGE as the authoritative source.\n",
    "\n",
    "2. First determine whether the document IS a demand letter.  \n",
    "   If NOT a demand letter:  \n",
    "   - \"is_demand_letter\" = false  \n",
    "   - All other fields MUST be null (including \"letter_response_markdown\").  \n",
    "   - Return the JSON and stop.\n",
    "\n",
    "3. If it IS a demand letter:  \n",
    "   - Extract all fields strictly from the provided content.  \n",
    "   - Use null for any field not explicitly present.  \n",
    "   - Do not infer, guess, or hallucinate any information.\n",
    "\n",
    "4. For \"evidence_attached\":  \n",
    "   - Provide an array of evidence types ONLY if explicitly attached or referenced.  \n",
    "   - Otherwise leave as an empty array.\n",
    "\n",
    "5. The field \"letter_response_markdown\" must contain a short, professional acknowledgement letter from the insurance adjuster.  \n",
    "   Requirements:  \n",
    "   - No salutation (“Dear…”).  \n",
    "   - No names of adjusters.  \n",
    "   - Must acknowledge receipt of the demand.  \n",
    "   - Must state the claim is under review.  \n",
    "   - Must summarize ONLY verifiable facts present in the letter.  \n",
    "   - Must mention a 30-day review/response timeline.  \n",
    "   - No additional claims, legal commentary, or invented facts.\n",
    "\n",
    "6. Use consistent, neutral, factual language.  \n",
    "   Never fabricate legal, financial, or policy details.\n",
    "\n",
    "7. When reading images, pay attention to:  \n",
    "   - Headers (law office, claimant, insurer)  \n",
    "   - Stamps, dates, letterheads  \n",
    "   - Signatures  \n",
    "   - Embedded exhibits  \n",
    "   - Handwritten annotations  \n",
    "   - Policy numbers, claim numbers  \n",
    "   - Amounts demanded  \n",
    "\n",
    "8. Your output must be **strict JSON**, parsable with no trailing text or commentary.\n",
    "\n",
    "Now analyze the provided text and images and return ONLY the JSON object.\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed675dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "_model_lock=threading.Lock()\n",
    "_model_instance=None\n",
    "_processor_instance=None\n",
    "\n",
    "def get_model_and_processor():\n",
    "    global _model_instance,_processor_instance\n",
    "    if _model_instance is not None:\n",
    "        return _model_instance,_processor_instance\n",
    "    with _model_lock:\n",
    "        if _model_instance is None:\n",
    "            _model_instance=Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "                \"Qwen/Qwen2.5-VL-7B-Instruct\", torch_dtype=\"auto\", device_map=\"auto\"\n",
    "            )\n",
    "            _processor_instance=AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "    return _model_instance,_processor_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "def extract_pdf_pages(pdf_path:str):\n",
    "    pdf=fitz.open(pdf_path)\n",
    "    out=[]\n",
    "    for page in pdf:\n",
    "        text=page.get_text()\n",
    "        pix=page.get_pixmap(dpi=200)\n",
    "        fn=f\"/tmp/page_{uuid.uuid4()}.png\"\n",
    "        pix.save(fn)\n",
    "        out.append({\"text\":text,\"image_path\":fn})\n",
    "    return out\n",
    "\n",
    "def analyze_pdf_local(pdf_path):\n",
    "    model,processor=get_model_and_processor()\n",
    "    pages=extract_pdf_pages(pdf_path)\n",
    "    msgs=[{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\": MASTER_PROMPT}]}]\n",
    "    for p in pages:\n",
    "        msgs[0][\"content\"].append({\"type\":\"image\",\"image\":p[\"image_path\"]})\n",
    "        msgs[0][\"content\"].append({\"type\":\"text\",\"text\":p[\"text\"]})\n",
    "    txt=processor.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
    "    imgs,vids=process_vision_info(msgs)\n",
    "    inputs=processor(text=[txt], images=imgs, videos=vids, padding=True, return_tensors=\"pt\")\n",
    "    inputs=inputs.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        gen=model.generate(**inputs, max_new_tokens=2048)\n",
    "    trimmed=[o[len(i):] for i,o in zip(inputs.input_ids,gen)]\n",
    "    out=processor.batch_decode(trimmed, skip_special_tokens=True)[0]\n",
    "    return DemandLetterExtract.parse_raw(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "def analyze_pdf_udf_impl(p):\n",
    "    try:\n",
    "        if p is None: return json.dumps({\"error\":\"null path\"})\n",
    "        r=analyze_pdf_local(p)\n",
    "        return r.json()\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\":str(e),\"path\":p})\n",
    "\n",
    "analyze_pdf_udf=udf(analyze_pdf_udf_impl,StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c202424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "df=spark.createDataFrame([\n",
    "    (\"/data/pdfs/sample1.pdf\",),\n",
    "    (\"/data/pdfs/sample2.pdf\",)\n",
    "],[\"pdf_path\"])\n",
    "\n",
    "scored=df.withColumn(\"analysis\", analyze_pdf_udf(\"pdf_path\"))\n",
    "scored.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
